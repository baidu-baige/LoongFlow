# Global directory configuration
workspace_path: "./output"

# Global LLM configuration (optional)
# If evaluator or other components do not have their own llm_config, this configuration will be used
llm_config:
  url: "http://xxx/v1"
  api_key: "******"
  model: "deepseek-r1-250528"
  temperature: 0.8
  context_length: 128000
  max_tokens: 32768
  top_p: 1.0
  timeout: 1200

# ------------------------------------------------------------------------------
# Define the configuration for all available components
# ------------------------------------------------------------------------------

# All available Configuration for Planner
planners:
  evolve_planner:
    # Planner's specific configuration, such as prompt templates, used LLM, etc.
    react_max_steps: 10

# All available Executor configurations
executors:
  evolve_executor_react:
    # ExecutorReact's specific configuration
    parallel_candidates: 2
    max_rounds: 3
    react_max_steps: 10

  evolve_executor_chat:
    # ExecutorChat's specific configuration
    max_rounds: 4

  evolve_executor_fuse:
    # ExecutorChat's specific configuration
    react_max_steps: 15
    score_threshold: 0.91
    max_rounds: 3
    chat_system_prompt: |
      We are currently using an Algorithm Evolve Paradigm (Evolux) to solve an evolve task. In Evolux, there are three phases:

      Phase 1: Planner. Planner is responsible for sampling the parent solution based on the task objectives, analyzing the current database status using a global perspective, and designing a generation plan for the next iteration, with the aim of achieving linear optimization based on the parent and solve the task.
      Phase 2: Executor. Executor is responsible for following the generation plan and the sampled parent solution, based on the task objectives, generate a new child solution that passes evaluation and get a higher evaluation score than the parent.
      Phase 3: Summary. Summary is responsible for reviewing the lessons learned from the child solution, if the evaluation results are better than the parent solution, successful experiences are summarized; otherwise, failures are summarized. The child generation source tracing path is recorded, and the sampling weight of the parent for next iteration in the database are updated.

      This achieves a self-evolutionary closed loop across Phases 1, 2 and 3.

      Now You are **Phase 2: Executor** in the Evolux Evolution Paradigm. Your responsibility is to remember the task information and, based on the sampled parent solution and generation plan, generate a child solution which can pass the evaluation.

      VERY IMPORTANT: You MUST remember the task information and ensure that the code is generated strictly followed by the plan.
      VERY IMPORTANT: You are the SECOND Phase of Evolux, your generated solution is the most important part. If you come up with a bad child solution, which does not pass the evaluation, it will slow down the entire evolutionary process, cause significant losses in time and money, this is UNACCEPTABLE. If this happens, you will be PUNISHED and DISMISSED.

      Code Generation Requirements[VERY IMPORTANT]:
        You must fully implement the search_for_best_set method, and the parameters and return value must be:
            from typing import Tuple
            def search_for_best_set() -> Tuple[np.ndarray, str].

        In your search_for_best_set function, you may call the get_score method for optimization, with the goal of maximizing the final result score.
        You must from typing import Tuple, from numba import njit, and other necessary imports.
        You must use Python int type, NOT use np.int64 or np.uint64.
        When generating the code, apart from the search_for_best_set function you implement, you must also return the following code simultaneously. The following code cannot be modified and must be returned exactly as is. The methods get_score and get_score_numba within the code below must remain unchanged. Code:

        def get_score(best_list):
            """Returns the score for the given list using Numba."""
            if isinstance(best_list, np.ndarray):
                best_list = best_list.tolist()

            try:
                best_list = [int(x) for x in best_list]
            except (ValueError, TypeError):
                print(f"get_score List contains non-convertible values: {best_list}")
                return 0

            if len(best_list) < 2:
                print(f"get_score List is too short: {best_list}")
                return 0

            # if the list contains non-integers, return 0
            if not all(isinstance(x, int) for x in best_list):
                print(f"get_score List contains non-integers: {best_list}")
                return 0

            return get_score_numba(best_list) + (1.0 - 1.0 / len(set(best_list))) / 100.0

        from numba import njit
        @njit
        def get_score_numba(best_list):
            """Returns the score for the given list using Numba."""

            best_list_set = set(best_list)
            n_unique = len(best_list_set)

            a_minus_a = set()
            for i in best_list:
                for j in best_list:
                    a_minus_a.add(i - j)

            a_plus_a = set()
            for i in best_list:
                for j in best_list:
                    a_plus_a.add(i + j)

            lhs = len(a_minus_a) / n_unique
            rhs = len(a_plus_a) / n_unique

            try:
                return math.log(rhs) / math.log(lhs)
            except Exception:
                return 0

# All available Summarizer configurations
summarizers:
  evolve_summary:
    # Summarizer's specific configuration
    react_max_steps: 10
# ------------------------------------------------------------------------------
# Define the main evolution process configuration
# ------------------------------------------------------------------------------
evolve:
  # Task description, is the core objective of the entire evolution process
  task: |
    Ruzsa's inequality problem

    Act as an expert software developer and optimization specialist specializing in creating python lists of distinct integers with certain properties. Your task is to find a python list A consisting distinct integers wit the property that the set A - A is as large as possible, and at the same time the set A + A is as small as possible. Here A + A is the set of all possible sums of two elements of A.

    Your task is to write a search function that searches for the best list. You may choose n, the length of the list, to be anything in this experiment. Larger values of n have more potential for bigger scores, but the search space is larger so they are harder to find. You'll have to balance it accordingly!

    [IMPORTANT]You must write search_for_best_set function and return Tuple[np.ndarray, str] !!!
    [IMPORTANT]You must refer to the get_score method in the previous code and place the provided get_score method code intact in the new code you generate, and you must not modify the get_score method

    Good luck, you've got this!

  # Name of the component selected for current run
  planner_name: "evolve_planner"
  executor_name: "evolve_executor_fuse"
  summary_name: "evolve_summary"

  # Core parameters for the evolution process
  max_iterations: 1000
  target_score: 1.0
  concurrency: 3

  # Evaluator configuration
  evaluator:
    timeout: 1200

  # Database configuration
  database:
    storage_type: "in_memory"
    num_islands: 3
    population_size: 30
    checkpoint_interval: 2
    # If sampling_weight_power < 1, sampling weight has a weak effect
    sampling_weight_power: 5
